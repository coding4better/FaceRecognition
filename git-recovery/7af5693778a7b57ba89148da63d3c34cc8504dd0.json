D:\Python_Environment\face2\Scripts\python.exe F:\study\project\face\face_train.py
Using TensorFlow backend.
D:\Python_Environment\face2\lib\site-packages\tensorflow\python\framework\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
D:\Python_Environment\face2\lib\site-packages\tensorflow\python\framework\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
D:\Python_Environment\face2\lib\site-packages\tensorflow\python\framework\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
D:\Python_Environment\face2\lib\site-packages\tensorflow\python\framework\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
D:\Python_Environment\face2\lib\site-packages\tensorflow\python\framework\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
D:\Python_Environment\face2\lib\site-packages\tensorflow\python\framework\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
(4110, 64, 64, 3)
[0 0 0 ... 2 2 2]
1
2877 train samples
1233 valid samples
2055 test samples
1 <class '__main__.Dataset'>
dataset.input_shape (64, 64, 3)
F:\study\project\face\face_train.py:109: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., padding="same")`
  input_shape=dataset.input_shape))  # 1 2维卷积层
F:\study\project\face\face_train.py:112: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`
  self.model.add(Convolution2D(32, 3, 3))  # 3 2维卷积层
F:\study\project\face\face_train.py:115: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format="channels_first")`
  self.model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering="th"))  # 5 池化层
F:\study\project\face\face_train.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding="same")`
  self.model.add(Convolution2D(64, 3, 3, border_mode='same'))  # 7  2维卷积层
F:\study\project\face\face_train.py:121: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding="same")`
  self.model.add(Convolution2D(64, 3, 3, border_mode='same'))  # 9  2维卷积层
F:\study\project\face\face_train.py:124: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format="channels_first")`
  self.model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering="th"))  # 11 池化层
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 64, 64, 32)        896
_________________________________________________________________
activation_1 (Activation)    (None, 64, 64, 32)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 62, 62, 32)        9248
_________________________________________________________________
activation_2 (Activation)    (None, 62, 62, 32)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 62, 31, 16)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 62, 31, 16)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 62, 31, 64)        9280
_________________________________________________________________
activation_3 (Activation)    (None, 62, 31, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 62, 31, 64)        36928
_________________________________________________________________
activation_4 (Activation)    (None, 62, 31, 64)        0
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 62, 15, 32)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 62, 15, 32)        0
_________________________________________________________________
flatten_1 (Flatten)          (None, 29760)             0
_________________________________________________________________
dense_1 (Dense)              (None, 512)               15237632
_________________________________________________________________
activation_5 (Activation)    (None, 512)               0
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 2565
_________________________________________________________________
activation_6 (Activation)    (None, 5)                 0
=================================================================
Total params: 15,296,549
Trainable params: 15,296,549
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_5 (Conv2D)            (None, 64, 64, 32)        896
_________________________________________________________________
activation_7 (Activation)    (None, 64, 64, 32)        0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 62, 62, 32)        9248
_________________________________________________________________
activation_8 (Activation)    (None, 62, 62, 32)        0
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 62, 31, 16)        0
_________________________________________________________________
dropout_4 (Dropout)          (None, 62, 31, 16)        0
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 62, 31, 64)        9280
_________________________________________________________________
activation_9 (Activation)    (None, 62, 31, 64)        0
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 62, 31, 64)        36928
_________________________________________________________________
activation_10 (Activation)   (None, 62, 31, 64)        0
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 62, 15, 32)        0
_________________________________________________________________
dropout_5 (Dropout)          (None, 62, 15, 32)        0
_________________________________________________________________
flatten_2 (Flatten)          (None, 29760)             0
_________________________________________________________________
dense_3 (Dense)              (None, 512)               15237632
_________________________________________________________________
activation_11 (Activation)   (None, 512)               0
_________________________________________________________________
dropout_6 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_4 (Dense)              (None, 5)                 2565
_________________________________________________________________
activation_12 (Activation)   (None, 5)                 0
=================================================================
Total params: 15,296,549
Trainable params: 15,296,549
Non-trainable params: 0
_________________________________________________________________
(2877, 64, 64, 3)
F:\study\project\face\face_train.py:181: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.
  validation_data=(dataset.valid_images, dataset.valid_labels))
F:\study\project\face\face_train.py:181: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=(array([[[..., steps_per_epoch=143, epochs=10)`
  validation_data=(dataset.valid_images, dataset.valid_labels))
Epoch 1/10
2023-04-07 21:15:50.416544: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
143/143 [==============================] - 57s - loss: 1.4601 - acc: 0.3657 - val_loss: 1.4019 - val_acc: 0.3982
Epoch 2/10
143/143 [==============================] - 92s - loss: 1.1079 - acc: 0.5469 - val_loss: 0.7479 - val_acc: 0.7048
Epoch 3/10
143/143 [==============================] - 157s - loss: 0.8632 - acc: 0.6468 - val_loss: 0.5684 - val_acc: 0.7883
Epoch 4/10
143/143 [==============================] - 168s - loss: 0.6494 - acc: 0.7401 - val_loss: 0.4855 - val_acc: 0.7770
Epoch 5/10
143/143 [==============================] - 147s - loss: 0.5658 - acc: 0.7749 - val_loss: 0.3768 - val_acc: 0.8881
Epoch 6/10
143/143 [==============================] - 148s - loss: 0.4936 - acc: 0.7995 - val_loss: 0.2880 - val_acc: 0.8913
Epoch 7/10
143/143 [==============================] - 133s - loss: 0.4250 - acc: 0.8284 - val_loss: 0.2710 - val_acc: 0.9197
Epoch 8/10
143/143 [==============================] - 65s - loss: 0.4107 - acc: 0.8401 - val_loss: 0.2894 - val_acc: 0.8856
Epoch 9/10
143/143 [==============================] - 110s - loss: 0.3798 - acc: 0.8530 - val_loss: 0.2654 - val_acc: 0.8938
Epoch 10/10
143/143 [==============================] - 145s - loss: 0.3314 - acc: 0.8824 - val_loss: 0.2284 - val_acc: 0.9116
(8220, 64, 64, 3)
[0 0 0 ... 2 2 2]
1
5754 train samples
2466 valid samples
4110 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_9 (Conv2D)            (None, 64, 64, 32)        896
_________________________________________________________________
activation_13 (Activation)   (None, 64, 64, 32)        0
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 62, 62, 32)        9248
_________________________________________________________________
activation_14 (Activation)   (None, 62, 62, 32)        0
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 62, 31, 16)        0
_________________________________________________________________
dropout_7 (Dropout)          (None, 62, 31, 16)        0
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 62, 31, 64)        9280
_________________________________________________________________
activation_15 (Activation)   (None, 62, 31, 64)        0
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 62, 31, 64)        36928
_________________________________________________________________
activation_16 (Activation)   (None, 62, 31, 64)        0
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 62, 15, 32)        0
_________________________________________________________________
dropout_8 (Dropout)          (None, 62, 15, 32)        0
_________________________________________________________________
flatten_3 (Flatten)          (None, 29760)             0
_________________________________________________________________
dense_5 (Dense)              (None, 512)               15237632
_________________________________________________________________
activation_17 (Activation)   (None, 512)               0
_________________________________________________________________
dropout_9 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_6 (Dense)              (None, 5)                 2565
_________________________________________________________________
activation_18 (Activation)   (None, 5)                 0
=================================================================
Total params: 15,296,549
Trainable params: 15,296,549
Non-trainable params: 0
_________________________________________________________________
(5754, 64, 64, 3)
F:\study\project\face\face_train.py:181: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=(array([[[..., steps_per_epoch=287, epochs=10)`
  validation_data=(dataset.valid_images, dataset.valid_labels))
Epoch 1/10
287/287 [==============================] - 303s - loss: 1.1550 - acc: 0.5176 - val_loss: 0.5777 - val_acc: 0.8333
Epoch 2/10
287/287 [==============================] - 204s - loss: 0.6494 - acc: 0.7294 - val_loss: 0.2685 - val_acc: 0.9465
Epoch 3/10
287/287 [==============================] - 320s - loss: 0.4237 - acc: 0.8398 - val_loss: 0.1290 - val_acc: 0.9627
Epoch 4/10
287/287 [==============================] - 312s - loss: 0.2941 - acc: 0.8899 - val_loss: 0.0583 - val_acc: 0.9858
Epoch 5/10
287/287 [==============================] - 310s - loss: 0.1378 - acc: 0.9517 - val_loss: 0.0139 - val_acc: 0.9976
Epoch 6/10
287/287 [==============================] - 312s - loss: 0.0965 - acc: 0.9688 - val_loss: 0.0092 - val_acc: 0.9976
Epoch 7/10
287/287 [==============================] - 313s - loss: 0.0854 - acc: 0.9703 - val_loss: 0.0036 - val_acc: 0.9992
Epoch 8/10
287/287 [==============================] - 325s - loss: 0.0635 - acc: 0.9784 - val_loss: 0.0154 - val_acc: 0.9968
Epoch 9/10
287/287 [==============================] - 332s - loss: 0.0558 - acc: 0.9821 - val_loss: 0.0017 - val_acc: 0.9992
Epoch 10/10
287/287 [==============================] - 332s - loss: 0.0627 - acc: 0.9789 - val_loss: 0.0623 - val_acc: 0.9745
dataset.input_shape (64, 64, 3)
(12330, 64, 64, 3)
[0 0 0 ... 2 2 2]
1
8631 train samples
3699 valid samples
6165 test samples
dataset.input_shape (64, 64, 3)
6165/6165 [==============================] - 105s
acc: 97.42%

进程已结束,退出代码0
